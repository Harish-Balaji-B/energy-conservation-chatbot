{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "Lv6ANJ7lmXWs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install streamlit_chat\n",
        "!pip install -q streamlit\n",
        "!pip install streamlit\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "C5SqDUwPr96q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from streamlit_chat import message\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "import openai\n",
        "\n",
        "import openai\n",
        "\n",
        "def get_initial_message():\n",
        "    messages=[\n",
        "            {\"role\": \"user\", \"content\": \"What type of bot are you?\"},\n",
        "            {\"role\": \"system\", \"content\": \"You are a chatbot who answers questions about Energy Conservation and Green Energy\"},\n",
        "            {\"role\": \"user\", \"content\": \"I want to know about Green Energy\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Thats awesome, what do you want to know aboout Green Energy\"},\n",
        "            {\"role\": \"user\", \"content\": \"I want to know about my energy consumption.\"},\n",
        "            {\"role\": \"user\", \"content\": \"Hello.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"Hello! I am a chatbot designed to answer your questions related to energy conservation and consumption\"}\n",
        "        ]\n",
        "    return messages\n",
        "\n",
        "def get_chatgpt_response(messages, model=\"gpt-3.5-turbo\"):\n",
        "    print(\"model: \", model)\n",
        "    response = openai.ChatCompletion.create(\n",
        "    model=model,\n",
        "    messages=messages\n",
        "    )\n",
        "    return  response['choices'][0]['message']['content']\n",
        "\n",
        "def update_chat(messages, role, content):\n",
        "    messages.append({\"role\": role, \"content\": content})\n",
        "    return messages\n",
        "\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "st.title(\"Your friendly power guide!!\")\n",
        "st.subheader(\"PowerBot: Power Conservation & Green Energy bot\")\n",
        "\n",
        "model = \"gpt-3.5-turbo\"\n",
        "if 'generated' not in st.session_state:\n",
        "    st.session_state['generated'] = []\n",
        "if 'past' not in st.session_state:\n",
        "    st.session_state['past'] = []\n",
        "\n",
        "query = st.text_input(\"Query: \", key=\"input\")\n",
        "\n",
        "if 'messages' not in st.session_state:\n",
        "    st.session_state['messages'] = get_initial_message()\n",
        "if query:\n",
        "    with st.spinner(\"generating...\"):\n",
        "        messages = st.session_state['messages']\n",
        "        messages = update_chat(messages, \"user\", query)\n",
        "        response = get_chatgpt_response(messages, model)\n",
        "        messages = update_chat(messages, \"assistant\", response)\n",
        "        st.session_state.past.append(query)\n",
        "        st.session_state.generated.append(response)\n",
        "if st.session_state['generated']:\n",
        "\n",
        "    for i in range(len(st.session_state['generated'])-1, -1, -1):\n",
        "        message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')\n",
        "        message(st.session_state[\"generated\"][i], key=str(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR9bX3J8ZnNR",
        "outputId": "d610a29b-3766-41d1-83e1-3b1b058a7660"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "wi8hpgAGlOuA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "LtWoSb_7lXrZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtPvXsw3lcfM",
        "outputId": "b0719f79-f0f4-493b-bd1d-86e6e3266a2a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.478s\n",
            "your url is: https://six-ducks-drum-34-141-135-76.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}
